{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "def svd_rot(M):\n",
    "    U, _, VT = np.linalg.svd(M)\n",
    "    V = VT.T\n",
    "    R = U @ V.T\n",
    "    if np.linalg.det(R) < 0:\n",
    "        V[:, -1] *= -1\n",
    "        R = U @ V.T\n",
    "    return R\n",
    "\n",
    "def rigid_transform(ps, qs):\n",
    "    \n",
    "    pmean = np.mean(ps, axis=0)\n",
    "    qmean = np.mean(qs, axis=0)\n",
    "    pbars = ps - pmean\n",
    "    qbars = qs - qmean\n",
    "\n",
    "    # project onto space of orthogonal matrices\n",
    "    M = qbars.T @ pbars\n",
    "    R = svd_rot(M)\n",
    "    t = qmean - R @ pmean\n",
    "\n",
    "    # write transformation matrix\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    return T\n",
    "\n",
    "\n",
    "def sample_3d_point(r=1):\n",
    "    rho = r * (1 + (np.random.rand() / 2))\n",
    "    theta = np.random.rand() * 2 * np.pi\n",
    "    phi = np.random.rand() * np.pi\n",
    "    return np.array([\n",
    "        rho * np.cos(theta) * np.sin(phi),\n",
    "        rho * np.sin(theta) * np.sin(phi),\n",
    "        rho * np.cos(phi),\n",
    "    ])\n",
    "\n",
    "def R_and_T(T):\n",
    "    return T[:3, :3], T[:3, 3]\n",
    "\n",
    "def icp(source_pcd, target_pcd, max_attempts=10, max_iters=1000, finish_loop_thresh=1e-5, acceptable_thresh=1e-5, pbar=False, seed=0):\n",
    "    \"\"\"Iterative closest point.\n",
    "    \n",
    "    Args:\n",
    "        source_pcd (np.ndarray): [N1, 3]\n",
    "        target_pcd (np.ndarray): [N2, 3]\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: [4, 4] rigid transformation to align source to target.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    targ_center = np.mean(target_pcd, axis=0)\n",
    "    targ_rad = np.max(np.linalg.norm(target_pcd - targ_center, axis=1))\n",
    "\n",
    "    attempt_dists = []\n",
    "    attempt_Ts = []\n",
    "\n",
    "    attempt_iter = tqdm(range(max_attempts)) if pbar else range(max_attempts)\n",
    "    for attempt in attempt_iter:\n",
    "\n",
    "        ps = source_pcd \n",
    "        # for retries:\n",
    "        # (1) move to point on 4*targ_rad ball around targ pcd\n",
    "        # (2) randomly rotate\n",
    "        if attempt > 0:\n",
    "            ps = ps - np.mean(ps, axis=0) + targ_center\n",
    "            ps = ps + sample_3d_point(r = 2 * targ_rad)\n",
    "            ps = ps @ svd_rot(np.random.rand(3, 3))\n",
    "\n",
    "        last_dist = np.inf\n",
    "\n",
    "        tree = scipy.spatial.KDTree(target_pcd)\n",
    "        qs = target_pcd[tree.query(ps)[1]]\n",
    "        for _ in range(max_iters):\n",
    "\n",
    "            # get transformation\n",
    "            T = rigid_transform(ps, qs)\n",
    "\n",
    "            # transform pt cld\n",
    "            ps = ps @ T[:3, :3].T + T[:3, 3]\n",
    "\n",
    "            # update qs\n",
    "            qs = target_pcd[tree.query(ps)[1]]\n",
    "\n",
    "            # if avg_dist doesn't change, ret early, else keep going\n",
    "            avg_dist = np.mean(np.linalg.norm(ps - qs, axis=1))\n",
    "            if np.abs(avg_dist - last_dist) <= finish_loop_thresh:\n",
    "                break\n",
    "            last_dist = avg_dist\n",
    "        \n",
    "        # if error acceptably small, continue\n",
    "        T = rigid_transform(source_pcd, ps)\n",
    "        if avg_dist <= acceptable_thresh:\n",
    "            return T\n",
    "            \n",
    "        # else, we save all Ts and ret whichever is best\n",
    "        attempt_dists.append(avg_dist)\n",
    "        attempt_Ts.append(T)\n",
    "\n",
    "    # ret transformation\n",
    "    return attempt_Ts[np.argmin(attempt_dists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(ds, data_idx, pose_evaluator, max_attempts=100, max_iters=1000):\n",
    "    from learning.utils import IDX_TO_OBJ_NAMES\n",
    "    cloud, model, obj_idx, pose = ds[data_idx]\n",
    "    if len(cloud) < 1:\n",
    "        R_pred, t_pred = R_and_T(np.eye(4))\n",
    "    else:\n",
    "        R_pred_cloud, t_pred_cloud = R_and_T(icp(cloud, model, max_attempts=max_attempts, max_iters=max_iters))\n",
    "        R_pred, t_pred = R_and_T(rigid_transform(model, (model - t_pred_cloud) @ R_pred_cloud))\n",
    "    return pose_evaluator.evaluate(IDX_TO_OBJ_NAMES[obj_idx[0]], R_pred, pose[:3, :3], t_pred, pose[:3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_over_ds(data_dir='processed_for_icp/val', max_attempts=100, max_iters=1000):\n",
    "    from benchmark_utils.pose_evaluator import PoseEvaluator\n",
    "    pose_evaluator = PoseEvaluator()\n",
    "\n",
    "    from learning.load import PoseDataset\n",
    "    ds = PoseDataset(data_dir=data_dir, cloud=True, model=True, transform=None)\n",
    "    \n",
    "    successes, rre_syms, rres, rtes = [], [], [], []\n",
    "    pbar = tqdm(range(len(ds)))\n",
    "    for i in pbar:\n",
    "        eval = pred(ds, i, pose_evaluator, max_attempts=max_attempts, max_iters=max_iters)\n",
    "        rre_syms.append(eval['rre_symmetry'])\n",
    "        rres.append(eval['rre'])\n",
    "        rtes.append(eval['rte'])\n",
    "        successes.append(int(rre_syms[-1] <= 5 and rtes[-1] <= 0.01))\n",
    "        pbar.set_description('\\t'.join([\n",
    "            'running rates', f'success={np.mean(successes):.4f}',\n",
    "            f'rre_sym={np.mean(rre_syms):.4f}', f'rte={np.mean(rtes):.4f}']\n",
    "        ))\n",
    "    return np.mean(successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_over_ds(data_dir='processed_for_icp_2/val', max_attempts=10, max_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_over_ds(data_dir='processed_for_icp_2/val', max_attempts=100, max_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from learning.load import PoseDataset\n",
    "import pickle\n",
    "\n",
    "def pred_over_raw_data(output_json_name='icp_pred.json', processed_data_dir='processed_for_icp_2', max_attempts=100, max_iters=1000, thresh=1e-5):\n",
    "    def get_stripped_lines(fp, levels=[1, 2]):\n",
    "        return [x.strip() for x in open(fp, 'r').readlines() if int(x[0]) in levels]\n",
    "\n",
    "    raw_data_dir = Path('raw_data')\n",
    "    raw_test_dir = raw_data_dir / 'testing_data'\n",
    "    raw_test_obj_dir = raw_test_dir / 'v2.2'\n",
    "    processed_data_dir = Path(processed_data_dir)\n",
    "    processed_test_dir = processed_data_dir / 'test'\n",
    "\n",
    "    test_scene_names = get_stripped_lines(raw_test_dir / 'test.txt')\n",
    "    test_ds = PoseDataset(data_dir=processed_test_dir, train=False, cloud=True, model=True, transform=None)\n",
    "\n",
    "    data_point_num = 0\n",
    "    all_data = dict()\n",
    "    pbar = tqdm(test_scene_names)\n",
    "    for scene_name in pbar:\n",
    "        meta_path = raw_test_obj_dir / f'{scene_name}_meta.pkl'\n",
    "        meta = pickle.load(open(meta_path, 'rb'))\n",
    "\n",
    "        scene_data = dict(poses_world=[None] * 79)\n",
    "\n",
    "        for obj_id, obj_name in zip(meta['object_ids'], meta['object_names']):\n",
    "\n",
    "            pbar.set_description(f'dp_num={data_point_num}')\n",
    "\n",
    "            cloud, model, _ = test_ds[data_point_num]\n",
    "            if len(cloud) < 1:\n",
    "                T = np.eye(4)\n",
    "            else:\n",
    "                R_pred_cloud, t_pred_cloud = R_and_T(icp(cloud, model, max_attempts=max_attempts, max_iters=max_iters, finish_loop_thresh=thresh, acceptable_thresh=thresh))\n",
    "                T = rigid_transform(model, (model - t_pred_cloud) @ R_pred_cloud)\n",
    "\n",
    "            scene_data['poses_world'][obj_id] = T.tolist()\n",
    "\n",
    "            data_point_num += 1\n",
    "\n",
    "        all_data[scene_name] = scene_data\n",
    "\n",
    "    import json\n",
    "    with open(output_json_name, 'w') as fp:\n",
    "        json.dump(all_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_over_raw_data(output_json_name='icp_pred_no_thresh.json', processed_data_dir='icp/processed_for_icp_2',  max_attempts=100, max_iters=1000, thresh=-np.inf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse275",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
